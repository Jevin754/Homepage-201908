<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<!--<link href="css/bootstrap.min.css" rel="stylesheet">-->
	<title>Chinese SLR Dataset</title>
	<link href="../../css/mystyle.css" rel="stylesheet">

</head>
<!--<body style="width:980px;margin-left:auto;margin-right:auto;">-->
<body style="width:95%;margin-left:auto;margin-right:auto;">
<!--<p style="font-family:verdana; font-size:35px; color:#930">Welcome to Junfu Pu's homepage!</p>-->

<h1 align="center"; style="font-size:36px">Chinese Sign Language Recognition Dataset</h1>
<h2 align="center">University of Science and Technology of China</h2>
<h3 align="center">Multimedia Computing & Communication, SLR Group</h3>
<hr class="sec_line">

<h2>Introduction</h2>
<p class="textBlock">
	We have two Chinese sign language datasets for isolated Sign Language Recognition and continuous Sign Language Recognition, respectively. Both datasets are collected with Kinect 2.0 by 50 signers. Each signer perfors 5 times for every word (sentence). The sign videos are recorded with 30<i>fps</i>. The distance between the signers and Kinect is about 1.5 meters. Each instance in both datasets contains <b>RGB videos</b>, <b>depth videos</b>, and <b>3D joints information</b> of the signer.
<br><br>
	Since the dataset is recorded with Microsoft Kinect, there are three data modalities available:
	<ol>
		<li>RGB videos with resolution of 1280 x 720 pixels and frame rate of 30 fps.</li>
		<li>Depth videos with resolution of 512x 424 pixels and frame rate of 30 fps.</li>
		<li>Twenty-five skeleton joints locations of each frame.</li>
	</ol>
</p>

<h2>Isolated SLR</h2>
<p class="textBlock">
	If you use this Chinese isolated SLR dataset in your research, please cite the following papers: 
	<ul>
		<li>Jihai Zhang, Wengang Zhou, Chao Xie, Junfu Pu, and Houqiang Li, "Chinese Sign Language Recognition with Adaptive HMM," <i>IEEE International Conference on Multimedia and Expo (ICME)</i>, 2016.</li>
		<li>Junfu Pu, Wengang Zhou, and Houqiang Li, "Sign Language Recognition with Multi-modal Features," <i>Pacific-Rim Conference on Multimedia (PCM)</i>, 2016.</li>
		<li>Tao Liu, Wengang Zhou, and Houqiang Li, "Sign Language Recognition with Long Short Term Memory," <i>IEEE International Conference on Image Processing (ICIP)</i>, 2016.</li>
		<li>Junfu Pu, Wengang Zhou, Jihai Zhang, and Houqiang Li, "Sign Language Recognition Based on Trajectory Modeling with HMMs," <i>International Conference on Multimedia Modelling (MMM)</i>, 2016.</li>
	</ul>
</p>

<p class="textBlock">
	The isolated SLR dataset contains 500 Chinese sign words. Each sign video is performed by 50 signers with 5 times. Hence, there are 250 instances for each sign word.
	<br><br>
	You can download the RGB and Depth videos of the dataset here <a href="https://pan.baidu.com/s/1tdUdI_3Ius44__d9PzVRCA" target="_blank">Isolated SLR500 (RGB & Depth, 1 time each signer)</a>, or <a href="https://pan.baidu.com/s/1MrJK66VBr65zBmYR21XBXg" target="_blank">Isolated SLR500 (RGB, 5 times each signer)</a> [password: rvux].
	<br>
	Check the instruction to download here. <a href="http://home.ustc.edu.cn/~hagjie/" target="_blank">[How]</a>
	<br>
	Besides, the signer's skeleton joint information is available here <a href="https://pan.baidu.com/s/1rbxv2PAulaWgMKAv3hVNUg" target="_blank">Isolated SLR500 (Joints)</a>. [password: fwt7]
</p>

<h2>Continuous SLR</h2>
<p class="textBlock">
	If you use this Chinese continuous SLR dataset in your research, please cite this paper: 
	<ul>
		<li>Jie Huang, Wengang Zhou, Qilin Zhang, Houqiang Li and Weiping Li, "Video-based Sign Language Recognition without Temporal Segmentation," <i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2018.</li>
	</ul>
</p>
<p class="textBlock">
	Besides, you can refer to the following papers for continuous SLR published by our group:
	<ul>
		<li>Junfu Pu, Wengang Zhou, and Houqiang Li, "Dilated Convolutional Network with Iterative Optimization for Continuous Sign Language Recognition," <i>International Joint Conference on Artificial Intelligence (IJCAI)</i>, 2018.</li>
		<li>Dan Guo, Wengang Zhou, Meng Wang, and Houqiang Li, "Hierarchical LSTM for Sign Language Translation," <i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2018.</li>
	</ul>
</p>

<p class="textBlock">
	The corpus of continuous SLR dataset contains 100 Chinese sentence. There are 250 instances (50signers x 5times) for each sentence.
	<br><br>
	You can download the RGB videos of the continuous SLR dataset here <a href="https://pan.baidu.com/s/1jJgDHMQ" target="_blank">Continuous SLR100 (RGB)</a>. [password: ac52]
	<br>
</p>

<h2>Contact</h2>
<p class="textBlock">
	If you have any questions about the dataset and our papers, please feel free to contact us:
	<ul>
		<li><a href="http://staff.ustc.edu.cn/~lihq/English.html" target="_blank">Houqiang Li</a>, Professor, USTC, lihq AT ustc.edu.cn</li>
		<li><a href="http://staff.ustc.edu.cn/~zhwg" target="_blank">Wengang Zhou</a>, Associate Professor, USTC, zhwg AT ustc.edu.cn</li>
		<li><a href="http://home.ustc.edu.cn/~pjh" target="_blank">Junfu Pu</a>, Ph.D Candidate, USTC, pjh AT mail.ustc.edu.cn</li>
	</ul>
</p>

<br><br>
<div align="center"><a href="../../index.html" style="color:blue;font-size:3ex"><b>[Back to Homepage]</b></a></div>
<hr style="height:1px;border:none;border-top:1px solid #555555;" />
<div align="right" style="font-family:verdana;color:#800000">&copy; Junfu Pu 2018 &nbsp&nbsp&nbsp&nbsp&nbsp Last updated on Aug. 2, 2018</div>
<div style="width:400px;margin:0 auto">
<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=jWKtanh3GLIaA7YarJE404P09JqFOL2zKwXMRyyAEBE&cl=ffffff&w=a"></script>
</div>
<p><br><br><br></p>
</body>
</html>